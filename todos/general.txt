TODAY:


TODO:
* Make it possible to run the Stanford parser on an existing tokenization.

* Consider the quesion of "speech turns" -- should they be represented as separate trees?
  I suppose so (issue raised during the TLN meeting, Mai 18, Blois)
  -> JY, AL: it should be visible (colors, labels) who is speaking at a given moment.
     If there are many speakers for a given speech turn, they should be parsed separately,
     and visible as a part of the same speech turn, like this:

    <Turn 1>, <spk1>: ble ble ble
    <Turn 2>, <spk1>: ble ble ble ble
            , <spk2>: bla bla
            , <spk1>: blu blu bly
    <Turn 3>, <spk2>: ble ble ble


DONE:
* Keep the original sentences and show them on the right in the annotation tool 
* Compute the number of words in the files pre-selected by JY, too see what portion
  of 20000 words does it make.
* Adapt the ODIL format to account for the information about speakers
* We want to re-implement the entire processing pipeline.  Why?  So that we can
  call the Stanford parser on the units we want.  I.e., to simplify the task. 

  The processing pipeline was like this:
  * Simplification: just reading the ancor files and showing them in a simplified form.
    This step is no longer needed (or, at least, not exactly in this form).
    + BTW Question: should we keep the division of sections on episodes in the DB? 
  * Preprocessing: the fuction `Text -> Text` can stay as it is (for the lack of a better
    yet simple solution).  We will have to worry about the alignement later.
  * Parsing: nothing to change, really
  * Conversion to the ODIL format: nothing to change, really



WITHDRAWN:
* Re-implement the preparation function.
* Update the `convertPennFile` function in the `Penn` module (NOTE: just commented it out)
