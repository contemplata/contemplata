TODAY:
* Make it possible to run the Stanford parser on an existing tokenization.


TODO:

* Make it possible to remove tokens
* Related: make it posslbe to (i) join tokens, and (ii) split tokens (do we really
  need this?)
* Related: deal with empty phrases (such cases will occur, don't think there's
  anything to worry there).

* Make it possible for a speech turn to have several sentences (trees)

* Try to think of how to project the Rhapsody-style disfluency annotations
  to our context (cf. JY's idea of using "reparandum")
* Related: see what is done with *incises* in FTB

* Implement an inference-rules engine
* Related: make it possible to (i) apply the rules (manually, tree-scope?) and
  (ii) to validate them afterwards. How to implement ergonomically (ii) is an
  open question...



DONE:
* Keep the original sentences and show them on the right in the annotation tool 
* Compute the number of words in the files pre-selected by JY, too see what portion
  of 20000 words does it make.
* Adapt the ODIL format to account for the information about speakers
* We want to re-implement the entire processing pipeline.  Why?  So that we can
  call the Stanford parser on the units we want.  I.e., to simplify the task. 
* Consider the quesion of "speech turns" -- should they be represented as separate trees?
  I suppose so (issue raised during the TLN meeting, Mai 18, Blois)
  -> JY, AL: it should be visible (colors, labels) who is speaking at a given moment.
     If there are many speakers for a given speech turn, they should be parsed separately,
     and visible as a part of the same speech turn, like this:

    <Turn 1>, <spk1>: ble ble ble
    <Turn 2>, <spk1>: ble ble ble ble
            , <spk2>: bla bla
            , <spk1>: blu blu bly
    <Turn 3>, <spk2>: ble ble ble



WITHDRAWN:
* Re-implement the preparation function.
* Update the `convertPennFile` function in the `Penn` module (NOTE: just commented it out)
